综述：Fairness-Aware Graph Neural Networks: A Survey

| 论文名称 | 简介                                                                                                                                                                                                                                                  |
|:-----|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Subgroup Generalization and Fairness of Graph Neural Networks   | 泛化性能的理论研究有利于理解GNN模型的基本问题（如公平性），设计更好的学习方法.在合理的假设下，我们证明了测试子组和训练集之间的距离可能是影响该子组 GNN 性能的关键因素，这需要特别注意训练节点的选择以实现公平学习                                                                                                                                       |
| EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks  | 与现有对 GNN 模型进行去偏差的工作不同，我们的目标是通过向 GNN 提供偏差较少的数据来消除输入属性网络的偏差，以实现更公平的 GNN.                                                                                                                                                                              |
| BA-GNN: On Learning Bias-Aware Graph Neural Network  | 重点讨论了如何解决图上的偏差问题，并学习了一个对任意未知分布偏移具有鲁棒性的图神经网络模型。为了解决这个问题，我们提出了一种新的偏差感知图神经网络（BA-GNN）框架，通过学习不同分布中不变的节点表示来进行不变预测,BA-GNN 框架包含两个交互部分，一个用于偏差识别，另一个用于不变预测                                                                                                    |
| Chasing Fairness in Graphs: A GNN Architecture Perspective | 与多层感知相比，GNN 表现出更差的公平性能，因为它们的模型架构（即邻居聚合）放大了偏差。为此，我们的目标是通过新的 GNN 架构实现公平性。我们提出在 GNN 的统一优化框架内设计的公平消息传递（FMP）                                                                                                                                             |
| Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data  | 在半监督学习任务设计图神经网络中，我们提出了一种方法，即 Shift-Robust GNN (SR-GNN)，旨在解决有偏差的训练数据和图的真实推理分布之间的分布差异, SR-GNN 使 GNN 模型适应训练标记节点与数据集其余部分之间存在的分布变化                                                                                                                       |
| Temporal Debiasing using Adversarial Loss based GNN architecture for Crypto Fraud Detection  | 在本文中，我们表明，在数据集（椭圆数据集）中提供的事务特征集上学习的模型带有时间偏差，即它们高度依赖于它们发生的时间步长。部署时间偏差模型会限制其在未来时间步长上的性能。为了解决这个问题，我们提出了一种使用基于 GNN 的架构的时间去偏差技术，该技术通过欺诈分类和时间分类之间的对抗性学习来确保泛化。构建的对抗性损失优化了嵌入，以确保它们1.在欺诈分类任务上表现良好 2.不包含时间偏差。                                                  |
| Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure | 大多数图神经网络通过学习输入图和标签之间的相关性来预测未见过的图的标签。然而，通过对具有严重偏差的训练图进行图分类研究，令人惊讶的是，我们发现 GNN 总是倾向于探索虚假相关性来做出决策，即使因果相关性始终存在。这意味着在此类有偏差的数据集上训练的现有 GNN 将面临泛化能力较差的问题。通过从因果角度分析这个问题，我们发现从有偏差的图中解开因果和偏差潜变量的纠缠和去相关对于去偏差来说都是至关重要的。受此启发，我们提出了一个通用的解缠结 GNN 框架来分别学习因果子结构和偏差子结构。 |
| Interpreting Unfairness in Graph Neural Networks via Training Node Attribution | 了解预测偏差是如何产生的至关重要，因为它指导 GNN 去偏差机制的设计,大多数现有的工作绝大多数都集中在 GNN 去偏差上，但未能解释这种偏差是如何引起的.在本文中，我们研究了一个新问题，通过将其归因于训练节点的影响来解释 GNN 不公平性。最后，我们还演示了如何使用所提出的框架来消除 GNN 的偏差                                                                                             |
| GraphPatcher: Mitigating Degree Bias for Graph Neural Networks via Test-time Augmentation| 现有的工作通过派生指定的 GNN 架构或专门针对低度节点的训练策略来解决这个问题。这些方法虽然有效，但无意中创建了一种人为的分布外场景，其中模型在训练期间主要甚至仅观察低度节点，导致 GNN 原本表现良好的高度节点的性能下降.有鉴于此，我们提出了一个测试时间增强框架，即 GRAPHPATCHER，以增强低度节点上任何 GNN 的测试时间泛化                                                                         |
|CaDRec: Contextualized and Debiased Recommender Model|最近关于图神经网络（GNN）或去偏方法的工作取得了显着的成果。然而，它们仍然面临（1）由 GNN 递归卷积引起的过度平滑节点嵌入，以及（2）由于流行度和用户个人偏差而导致的交互分布不均。本文提出了一种情境化和去偏的推荐模型CaDRec                                                                                                                                                                                                                                                     |